{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from collections import Counter\n",
    "import json\n",
    "import datetime\n",
    "from html.parser import HTMLParser\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLStripper(HTMLParser):\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tself.reset()\n",
    "\t\tself.strict = False\n",
    "\t\tself.convert_charrefs = True\n",
    "\t\tself.fed = []\n",
    "\n",
    "\tdef handle_data(self, d):\n",
    "\t\tself.fed.append(d)\n",
    "\n",
    "\tdef get_data(self):\n",
    "\t\treturn ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "\n",
    "\ts = MLStripper()\n",
    "\ts.feed(html)\n",
    "\treturn s.get_data()\n",
    "    \n",
    "def read_json_tweets_file(myjsontweetfile, reqlang=['en','tr'], linecount=-1):\n",
    "\t\"Each tweet should be in a line. The parameter linecount restricts number of tweets in case it is not -1.\"\n",
    "\n",
    "\tftwits = []\n",
    "\tlang_cntr = Counter()\n",
    "\twith open(myjsontweetfile) as jfile:\n",
    "\t\tfor i, ln in enumerate(jfile):\n",
    "\t\t\tif i == linecount:  # restrict line numbers for test\n",
    "\t\t\t\tbreak\n",
    "\t\t\tt = json.loads(ln)\n",
    "\n",
    "\t\t\tif (\"lang\" in t):\n",
    "\t\t\t\tlang_cntr[t[\"lang\"]] += 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tlang_cntr[\"NoLang\"] += 1\n",
    "\n",
    "\t\t\tif (\"lang\" in t) and (t[\"lang\"] not in reqlang):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\telif (\"lang\" not in t) or (t[\"lang\"] in reqlang):\n",
    "\t\t\t\tt[\"created_at\"] = datetime.datetime.strptime(t[\"created_at\"], \"%a %b %d %H:%M:%S +0000 %Y\")\n",
    "\t\t\t\t# if t[\"created_at\"].strftime(\"%Y-%m-%d\") in flood_AnomBreakoutDaysList:\n",
    "\t\t\t\tif \"entities\" in t and \"media\" in t[\"entities\"]:\n",
    "\t\t\t\t\tfor tm in t[\"entities\"][\"media\"]:\n",
    "\t\t\t\t\t\tif tm[\"type\"] == 'photo':\n",
    "\t\t\t\t\t\t\tt[\"entity_type\"] = 'photo'\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\t\tif \"entities\" in t and \"hashtags\" in t[\"entities\"]:\n",
    "\t\t\t\t\tt[\"entity_hashtags\"] = [ehs[\"text\"] for ehs in t[\"entities\"][\"hashtags\"]]\n",
    "\t\t\t\n",
    "\t\t\t\tif \"entities\" in t and \"user_mentions\" in t[\"entities\"]:\n",
    "\t\t\t\t\tt[\"entity_mentions\"] = [ems[\"screen_name\"] for ems in t[\"entities\"][\"user_mentions\"]]\n",
    "\n",
    "\n",
    "\t\t\t\t# if \"entities\" in t and \"urls\" in t[\"entities\"]:\n",
    "\t\t\t\t# \tt[\"entity_urls\"] = [ers[\"display_url\"] for ers in t[\"entities\"][\"urls\"]]\n",
    "\n",
    "\t\t\t\tif \"entities\" in t and \"urls\" in t[\"entities\"]:\n",
    "\t\t\t\t\tt[\"entity_urls\"] = [ers.get(\"display_url\",None) for ers in t[\"entities\"][\"urls\"]]\n",
    "                    \n",
    "\t\t\t\tif 'full_text' in t:\n",
    "\t\t\t\t\tt['text'] = t['full_text']\n",
    "\n",
    "\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tif \"place\" in t:\n",
    "\t\t\t\t\t\tt[\"country\"] = t[\"place\"][\"country\"]\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tpass\n",
    "\t\t\t\tif \"retweeted_status\" in t:\n",
    "\t\t\t\t\tt[\"is_retweet\"] = True\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tt[\"is_retweet\"] = False\n",
    "\n",
    "\t\t\t\t\n",
    "\t\t\t\tif 'source' in t:\n",
    "\t\t\t\t\tt[\"device\"] = strip_tags(t[\"source\"])\n",
    "\n",
    "\t\t\t\tt[\"user_id\"] = t[\"user\"][\"id_str\"]\n",
    "\n",
    "\t\t\t\tif \"followers_count\" in t[\"user\"]:\n",
    "\t\t\t\t\tt[\"user_followers\"] = t[\"user\"][\"followers_count\"]\n",
    "\n",
    "\t\t\t\tif \"friends_count\" in t[\"user\"]:\n",
    "\t\t\t\t\tt[\"user_following\"] = t[\"user\"][\"friends_count\"]\n",
    "                    \n",
    "\t\t\t\tif 'location' in t['user']:\n",
    "\t\t\t\t\tt['user_location'] = t['user']['location']\n",
    "                    \n",
    "\t\t\t\tif 'name' in t['user']:\n",
    "\t\t\t\t\tt['user_name'] = t['user']['name']\n",
    "                    \n",
    "\t\t\t\tif 'description' in t['user']:\n",
    "\t\t\t\t\tt['user_description'] = t['user']['description']\n",
    "                    \n",
    "\t\t\t\tif 'statuses_count' in t['user']:\n",
    "\t\t\t\t\tt['user_statuses_count'] = t['user']['statuses_count']\n",
    "                    \n",
    "\t\t\t\tif 'created_at' in t['user']:\n",
    "\t\t\t\t\tt['user_created_at'] = t['user']['created_at']\n",
    "                    \n",
    "                    \n",
    "\t\t\t\tif 'extended_tweet' in t:\n",
    "\t\t\t\t\tt['text'] = t['extended_tweet']['full_text']\n",
    "                    \n",
    "\t\t\t\tif 'place' in t:\n",
    "\t\t\t\t\tt['tweet_location'] = t['place']['full_name']\n",
    "\n",
    "\t\t\t\tt[\"screen_name\"] = t[\"user\"][\"screen_name\"]\n",
    "\n",
    "\t\t\t\tt2 = {k:str(v) for k,v in t.items() if k in [\"entity_type\",\"entity_hashtags\",\"entity_mentions\",\"entity_urls\",\\\n",
    "\t\t\t\t\t\t\t\"country\",\"created_at\",\"text\",\"in_reply_to_user_id\",\"id_str\",\"user_id\",\\\n",
    "\t\t\t\t\t\t\t\"user_followers\",\"user_following\", \"coordinates\", \"is_retweet\",\"device\",\\\n",
    "\t\t\t\t\t\t\t\"screen_name\",'user_location','tweet_location','user_name',\\\n",
    "\t\t\t\t\t\t\t\"user_description\",\"user_statuses_count\",\"user_created_at\"]}\n",
    "                \n",
    "\t\t\t\t# print(i, end = ',')\n",
    "\t\t\t\tftwits.append(t2)  # .splitlines()\n",
    "\t\tprint(\"Number of documents per languge:\", lang_cntr)\n",
    "\t\treturn ftwits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "available_output_files = list(glob(\"_tweets_.json.xlsx\")) + glob(\"_tweets_.json.csv\")\n",
    "print(available_output_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_tweets_20210810.json\n",
      "Number of documents per languge: Counter({'tr': 24250})\n",
      "Total tweets until now: 24250\n",
      "24250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-53d32982fcc4>:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tw_df['text'] = tw_df.text.str.replace(r'[\\n\\t\\r]+',\" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23927\n"
     ]
    }
   ],
   "source": [
    "ftwits = []\n",
    "for twfile in glob(\"all_tweets_2021*.json\"):\n",
    "#     if twfile not in [\"202003030549_COVID-19_tweets_.json\",\"202002291512_coronavirus_tweets_.json\",\n",
    "#                      \"202003021010_outbreak_tweets_.json\",\"202003022001_2019-nCoV_tweets_.json\",]\n",
    "    print(twfile)\n",
    "    ftwits = read_json_tweets_file(twfile)\n",
    "    print(\"Total tweets until now:\", len(ftwits))\n",
    "    \n",
    "    tw_df = pd.DataFrame(ftwits)\n",
    "    print(len(tw_df))\n",
    "    tw_df.drop_duplicates(subset=['id_str'], inplace=True)\n",
    "    tw_df.drop_duplicates(subset=['text'], inplace=True)\n",
    "    tw_df['text'] = tw_df.text.str.replace(r'[\\n\\t\\r]+',\" \")\n",
    "    print(len(tw_df))\n",
    "    \n",
    "    if twfile+\".csv\" not in available_output_files:\n",
    "        tw_df.to_csv(twfile+\".csv\", sep='\\t')\n",
    "        \n",
    "    if twfile+\".xlsx\" not in available_output_files:\n",
    "        tw_df.to_excel(twfile+\".xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
